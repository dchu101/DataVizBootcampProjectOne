{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast \n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_df = pd.read_json('../reviews_Electronics_5.json', lines=True)\n",
    "#apps_df = pd.read_json('../reviews_Apps_for_Android_5.json', lines=True)\n",
    "cds_df = pd.read_json('../reviews_CDs_and_Vinyl_5.json', lines=True)\n",
    "#kindle_df = pd.read_json('../reviews_Kindle_Store_5.json', lines=True)\n",
    "#movies_tv_df = pd.read_json('../reviews_Movies_and_TV_5.json', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1262304000 is unix time for January 1, 2010\n",
    "\n",
    "electronics_df_cut = electronics_df[electronics_df['unixReviewTime'] > 1262304000]\n",
    "#apps_df_cut = apps_df[apps_df['unixReviewTime'] > 1262304000]\n",
    "cds_df_cut = cds_df[cds_df['unixReviewTime'] > 1262304000]\n",
    "#kindle_df_cut = kindle_df[kindle_df['unixReviewTime'] > 1262304000]\n",
    "#movies_tv_df_cut = movies_tv_df[movies_tv_df['unixReviewTime'] > 1262304000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/david/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "electronics_df_cut['category'] = 'Electronics'\n",
    "#apps_df_cut['category'] = 'Apps for Android'\n",
    "cds_df_cut['category'] = 'CDs and Vinyl'\n",
    "#kindle_df_cut['category'] = 'Kindle Store'\n",
    "#movies_tv_df_cut['category'] = 'Movies and TV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [electronics_df_cut, cds_df_cut]\n",
    "\n",
    "reviews_df = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = reviews_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_csv('reviews (no books).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_asin = set(reviews_df['asin'])\n",
    "\n",
    "unique_asin_list = pd.Series(list(unique_asin))\n",
    "\n",
    "unique_asin_list.to_csv('unique_asin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del electronics_df\n",
    "#del apps_df\n",
    "del cds_df\n",
    "#del kindle_df\n",
    "#del movies_tv_df\n",
    "\n",
    "del electronics_df_cut\n",
    "#del apps_df_cut\n",
    "del cds_df_cut\n",
    "#del kindle_df_cut\n",
    "#del movies_tv_df_cut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parses the meta data\n",
    "\n",
    "category = 'Books'\n",
    "\n",
    "path = ('../meta_' + category + '.json')\n",
    "\n",
    "# Start a pandas df to capture what we need from the metadata\n",
    "product_df = pd.DataFrame({})\n",
    "product_df['ASIN']=''\n",
    "product_df['Title']=''\n",
    "product_df['Sale Rank']=''\n",
    "\n",
    "start = time.time()\n",
    "total_logged =0\n",
    "logged = 0\n",
    "no_title = 0\n",
    "no_sales_rank = 0\n",
    "\n",
    "file_no = 1\n",
    "\n",
    "# open the json file with the ast modules so we can capture the values \n",
    "with open(path) as file:\n",
    "    for j,line in enumerate(file):\n",
    "        row = ast.literal_eval(line)\n",
    "        \n",
    "        if row['asin'] in unique_book_asin:\n",
    "            total_logged += 1\n",
    "            logged += 1\n",
    "            product_df.at[j,'ASIN'] = row['asin']\n",
    "            \n",
    "            try:\n",
    "                product_df.at[j,'Title'] = row['title']\n",
    "            except:\n",
    "                product_df.at[j,'Title'] = np.nan\n",
    "                no_title += 1\n",
    "            \n",
    "            try:\n",
    "                product_df.at[j,'Sale Rank'] = list(row['salesRank'].values())[0]\n",
    "            except:\n",
    "                product_df.at[j,'Sale Rank'] = np.nan\n",
    "                no_sales_rank += 1\n",
    "        if j > 0 and j % 10000 == 0:\n",
    "            time_elapsed = time.time() - start\n",
    "            print(f'Reach {j} rows of file. Logged for next file {logged}. Total log: {total_logged}. No title: {no_title}. No sales: {no_sales_rank}. Time elapsed: {time_elapsed}')\n",
    "            start = time.time()\n",
    "        \n",
    "        if logged == 10000:\n",
    "            \n",
    "            logged = 0\n",
    "            product_df.set_index('ASIN', inplace=True)\n",
    "            product_df.to_csv('meta_' + category + '_file' + str(file_no).zfill(4) + '.csv')\n",
    "            file_no += 1\n",
    "            del product_df\n",
    "            product_df = pd.DataFrame({})\n",
    "            product_df['ASIN']=''\n",
    "            product_df['Title']=''\n",
    "            product_df['Sale Rank']=''\n",
    "        \n",
    "\n",
    "print('Done.')\n",
    "\n",
    "#product_df = product_df.dropna(axis=0,how='any',subset=['ASIN'])\n",
    "#product_df = product_df.drop_duplicates(subset=['ASIN','Title'],keep='last')\n",
    "\n",
    "#product_df = product_df.set_index('ASIN')  \n",
    "#export to csv\n",
    "#print('Exporting to csv...')\n",
    "\n",
    "#output = 'Metadata Extract.csv'\n",
    "#product_df.to_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kindle1 = pd.read_csv('meta_Kindle_Store_file0001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kindle1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads the Books json, filters data, produces smaller csv files for iterative loading\n",
    "\n",
    "# path\n",
    "\n",
    "path = ('../../reviews_Books_5.json')\n",
    "\n",
    "# Start a pandas df to capture what we need from the metadata\n",
    "bookreviews_df = pd.DataFrame({})\n",
    "bookreviews_df['asin'] = ''\n",
    "bookreviews_df['helpful'] = ''\n",
    "bookreviews_df['overall'] = ''\n",
    "bookreviews_df['reviewText'] = ''\n",
    "bookreviews_df['reviewTime'] = ''\n",
    "''\n",
    "\n",
    "\n",
    "#'asin', 'category', 'helpful', 'overall', 'reviewText', 'reviewTime','reviewerID', 'reviewerName', 'summary', 'unixReviewTime'\n",
    "\n",
    "start = time.time()\n",
    "loop_start = time.time()\n",
    "total_logged =0\n",
    "logged = 0\n",
    "no_title = 0\n",
    "no_sales_rank = 0\n",
    "\n",
    "file_no = 1\n",
    "\n",
    "# open the json file with the ast modules so we can capture the values \n",
    "with open(path) as file:\n",
    "    for j,line in enumerate(file):\n",
    "        row = ast.literal_eval(line)\n",
    "        \n",
    "        if int(row['reviewTime'][-4:]) > 2009:\n",
    "\n",
    "            total_logged += 1\n",
    "            logged += 1\n",
    "\n",
    "            try:\n",
    "                bookreviews_df.at[j,'asin'] = row['asin']\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                bookreviews_df.at[j,'helpful'] = row['helpful']\n",
    "            except:\n",
    "                bookreviews_df.at[j,'helpful'] = np.nan\n",
    "\n",
    "            try:\n",
    "                bookreviews_df.at[j,'overall'] = row['overall']\n",
    "            except:\n",
    "                bookreviews_df.at[j,'overall'] = np.nan\n",
    "\n",
    "            try:\n",
    "                bookreviews_df.at[j,'reviewText'] = row['reviewText']\n",
    "            except:\n",
    "                bookreviews_df.at[j,'reviewText'] = np.nan\n",
    "            \n",
    "            try:\n",
    "                bookreviews_df.at[j,'reviewTime'] = row['reviewTime']\n",
    "            except:\n",
    "                bookreviews_df.at[j,'reviewTime'] = np.nan        \n",
    "    \n",
    "        if j > 0 and j % 100000 == 0:\n",
    "            time_elapsed = time.time() - loop_start\n",
    "            print(f'Reached {j} rows of file. Total logged: {total_logged}. Time elapsed: {time_elapsed}')\n",
    "            loop_start = time.time()\n",
    "        \n",
    "        if logged == 1000:\n",
    "            \n",
    "            logged = 0\n",
    "            bookreviews_df.set_index('asin', inplace=True)\n",
    "            bookreviews_df.to_csv('reviews_books_' + str(file_no).zfill(4) + '.csv')\n",
    "            file_no += 1\n",
    "            del bookreviews_df\n",
    "            bookreviews_df = pd.DataFrame({})\n",
    "            bookreviews_df['asin'] = ''\n",
    "            bookreviews_df['helpful'] = ''\n",
    "            bookreviews_df['overall'] = ''\n",
    "            bookreviews_df['reviewText'] = ''\n",
    "            bookreviews_df['reviewTime'] = ''\n",
    "        \n",
    "        #stops after 3 million reviews\n",
    "        if logged == 3000000:\n",
    "            break\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "\n",
    "for file_no in range(2, 7140):\n",
    "\n",
    "    filepath = 'Book Reviews/reviews_books_' + str(file_no).zfill(4) + '.csv'\n",
    "    file_names.append(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_review_df = pd.read_csv('Book Reviews/reviews_books_0001.csv')\n",
    "\n",
    "books_asin = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file in file_names:\n",
    "    i += 1\n",
    "    \n",
    "    book_review_append = pd.read_csv(file)\n",
    "    book_review_df = pd.concat([book_review_df, book_review_append])\n",
    "    book_review_df.reset_index(drop=True) \n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(file)\n",
    "    \n",
    "    if i == 100:\n",
    "        i = 0\n",
    "        books_asin.append(book_review_df['asin'])\n",
    "        book_review_df = pd.read_csv(file)\n",
    "    \n",
    "books_unique_asin = set(books_asin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = []\n",
    "\n",
    "for list in books_asin:\n",
    "    \n",
    "    add = list.tolist()\n",
    "    \n",
    "    for asin in add:\n",
    "        total.append(asin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_book_asin = set(total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
